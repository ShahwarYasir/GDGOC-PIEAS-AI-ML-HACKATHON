{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load Imports**"
      ],
      "metadata": {
        "id": "fb8LTH7d6UDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "xO4IZqSD45Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Functions**"
      ],
      "metadata": {
        "id": "6u7-qi-J6qEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def crop_black_border(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 15, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        cnt = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        img_cropped = img[y:y+h, x:x+w]\n",
        "        return cv2.resize(img_cropped, (224,224))\n",
        "    return cv2.resize(img, (224,224))\n",
        "\n",
        "def enhance_contrast(img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "    merged = cv2.merge((cl, a, b))\n",
        "    return cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)"
      ],
      "metadata": {
        "id": "Gnz0GyO548wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeuDuLjAzazK",
        "outputId": "bd19a484-c86e-4e6c-cbd6-837d393a12cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLAHE transform**"
      ],
      "metadata": {
        "id": "sC2akfD_7Hm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ApplyCLAHE:\n",
        "    def __init__(self, clip_limit=2.0, tile_grid_size=(8,8)):\n",
        "        self.clahe = cv2.createCLAHE(\n",
        "            clipLimit=clip_limit,\n",
        "            tileGridSize=tile_grid_size\n",
        "        )\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        enhanced = self.clahe.apply(gray)\n",
        "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)\n",
        "        return Image.fromarray(enhanced)\n"
      ],
      "metadata": {
        "id": "ukc0HsKf5B0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Class**"
      ],
      "metadata": {
        "id": "ZSW60FQt7UA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DRDataset(Dataset):\n",
        "    def __init__(self, base_path, split, transform=None):\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        split_path = os.path.join(base_path, split)\n",
        "        classes = sorted(os.listdir(split_path))\n",
        "        self.class_map = {cls: i for i, cls in enumerate(classes)}\n",
        "\n",
        "        for cls in classes:\n",
        "            cls_path = os.path.join(split_path, cls)\n",
        "            for img_name in os.listdir(cls_path):\n",
        "                self.images.append(os.path.join(cls_path, img_name))\n",
        "                self.labels.append(self.class_map[cls])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "fAoyslZY5DoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transforms**"
      ],
      "metadata": {
        "id": "sQK6JCJ67b9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    ApplyCLAHE(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    ApplyCLAHE(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "FxCtxUKT5FhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datasets & Loaders**"
      ],
      "metadata": {
        "id": "2uhBLWPZ7l1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/dataset/content/Diabetic_Balanced_Data\"\n",
        "\n",
        "train_dataset = DRDataset(base_path, \"train\", train_transforms)\n",
        "val_dataset   = DRDataset(base_path, \"val\", val_transforms)\n",
        "test_dataset  = DRDataset(base_path, \"test\", val_transforms)\n",
        "\n",
        "print(\"Train:\", len(train_dataset))\n",
        "print(\"Val:\", len(val_dataset))\n",
        "print(\"Test:\", len(test_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wT3pvYs5KSq",
        "outputId": "c0adde76-09da-4f22-e25d-1795e9a6f386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 34792\n",
            "Val: 9940\n",
            "Test: 4971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "u60wFZqt5Tdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "rspsA_oa0GK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Residual Block**"
      ],
      "metadata": {
        "id": "4f27L5jQ78TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=3,\n",
        "            stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels, out_channels, kernel_size=3,\n",
        "            stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n"
      ],
      "metadata": {
        "id": "bdqBdrQL0Mo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full CNN Model**"
      ],
      "metadata": {
        "id": "W0Qfdb398FoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DRResNet(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer0 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "6jYgIyRBEn2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = DRResNet(num_classes=5).to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLvg1F3TewD_",
        "outputId": "9a203c77-6767-4995-f90e-25adcd313401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DRResNet(\n",
            "  (layer0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASS-WEIGHTED LOSS**"
      ],
      "metadata": {
        "id": "39FVFp1q8MaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "labels = train_dataset.labels\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
      ],
      "metadata": {
        "id": "pA2BmqYyfsWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "NOCLrc_F15zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n"
      ],
      "metadata": {
        "id": "tiXGCM-B18g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.amp import autocast, GradScaler\n",
        "import os\n",
        "\n",
        "# Paths & device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "save_path = \"/content/shahwar_yasir/model/drresnet_best.pth\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 20\n",
        "scaler = GradScaler()\n",
        "best_val_acc = 0.0\n"
      ],
      "metadata": {
        "id": "LOOUp9Q71-xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**"
      ],
      "metadata": {
        "id": "ZACgykX68Sp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision with explicit device_type\n",
        "        with autocast(device_type='cuda'):\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        running_corrects += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    # Epoch metrics\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects / len(train_dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss_total = 0.0\n",
        "    val_corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss_total += loss.item() * imgs.size(0)\n",
        "            val_corrects += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss_total / len(val_dataset)\n",
        "    val_acc = val_corrects / len(val_dataset)\n",
        "\n",
        "    # Scheduler step\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "          f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "# Load best model after training\n",
        "print(f\"\\nBest Validation Accuracy: {best_val_acc:.4f}\")\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IofpWwNJ2J0N",
        "outputId": "930b5e89-09f9-4a46-c1ce-698c7786b62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] Train Loss: 1.2642, Train Acc: 0.4350 | Val Loss: 1.2415, Val Acc: 0.4530\n",
            "Epoch [2/20] Train Loss: 1.1650, Train Acc: 0.4873 | Val Loss: 1.3881, Val Acc: 0.4304\n",
            "Epoch [3/20] Train Loss: 1.1338, Train Acc: 0.4990 | Val Loss: 1.0989, Val Acc: 0.5174\n",
            "Epoch [4/20] Train Loss: 1.1047, Train Acc: 0.5127 | Val Loss: 1.0985, Val Acc: 0.5188\n",
            "Epoch [5/20] Train Loss: 1.0682, Train Acc: 0.5314 | Val Loss: 1.3536, Val Acc: 0.4578\n",
            "Epoch [6/20] Train Loss: 1.0335, Train Acc: 0.5483 | Val Loss: 1.1405, Val Acc: 0.5357\n",
            "Epoch [7/20] Train Loss: 1.0032, Train Acc: 0.5649 | Val Loss: 0.9788, Val Acc: 0.5778\n",
            "Epoch [8/20] Train Loss: 0.9702, Train Acc: 0.5814 | Val Loss: 0.9994, Val Acc: 0.5695\n",
            "Epoch [9/20] Train Loss: 0.9383, Train Acc: 0.5942 | Val Loss: 0.9309, Val Acc: 0.5994\n",
            "Epoch [10/20] Train Loss: 0.9009, Train Acc: 0.6119 | Val Loss: 0.9228, Val Acc: 0.5984\n",
            "Epoch [11/20] Train Loss: 0.8723, Train Acc: 0.6251 | Val Loss: 0.9691, Val Acc: 0.5900\n",
            "Epoch [12/20] Train Loss: 0.8340, Train Acc: 0.6445 | Val Loss: 0.8785, Val Acc: 0.6249\n",
            "Epoch [13/20] Train Loss: 0.7982, Train Acc: 0.6597 | Val Loss: 0.8312, Val Acc: 0.6456\n",
            "Epoch [14/20] Train Loss: 0.7614, Train Acc: 0.6762 | Val Loss: 0.8091, Val Acc: 0.6615\n",
            "Epoch [15/20] Train Loss: 0.7243, Train Acc: 0.6894 | Val Loss: 0.7698, Val Acc: 0.6753\n",
            "Epoch [16/20] Train Loss: 0.6970, Train Acc: 0.7011 | Val Loss: 0.7839, Val Acc: 0.6713\n",
            "Epoch [17/20] Train Loss: 0.6614, Train Acc: 0.7158 | Val Loss: 0.8431, Val Acc: 0.6430\n",
            "Epoch [18/20] Train Loss: 0.6307, Train Acc: 0.7323 | Val Loss: 0.7281, Val Acc: 0.6902\n",
            "Epoch [19/20] Train Loss: 0.6071, Train Acc: 0.7438 | Val Loss: 0.7831, Val Acc: 0.6724\n",
            "Epoch [20/20] Train Loss: 0.5777, Train Acc: 0.7557 | Val Loss: 0.6951, Val Acc: 0.7092\n",
            "\n",
            "Best Validation Accuracy: 0.7092\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DRResNet(\n",
              "  (layer0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate on Test Set**"
      ],
      "metadata": {
        "id": "QODYEoOH8azg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_corrects = 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        test_corrects += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "test_acc = test_corrects / len(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcB4pK6T2MJH",
        "outputId": "d557109b-dcdc-4e14-a6ea-50a58413e990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grad-CAM Visualization**"
      ],
      "metadata": {
        "id": "2VV-fD3Z8qbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "def visualize_gradcam(model, loader, target_layer, device, num_images=5):\n",
        "    model.eval()\n",
        "    images_shown = 0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(1)\n",
        "\n",
        "        # Hook for feature maps\n",
        "        activations = []\n",
        "        def hook_fn(module, input, output):\n",
        "            activations.append(output)\n",
        "\n",
        "        handle = target_layer.register_forward_hook(hook_fn)\n",
        "        _ = model(imgs)\n",
        "        handle.remove()\n",
        "\n",
        "        # Take first batch images for Grad-CAM\n",
        "        for i in range(min(num_images, imgs.size(0))):\n",
        "            img = imgs[i].cpu()\n",
        "            act = activations[0][i].detach().cpu()\n",
        "\n",
        "            # Compute heatmap\n",
        "            heatmap = act.mean(dim=0)\n",
        "            heatmap = heatmap - heatmap.min()\n",
        "            heatmap = heatmap / heatmap.max()\n",
        "\n",
        "            plt.figure(figsize=(5,5))\n",
        "            plt.imshow(to_pil_image(img))\n",
        "            plt.imshow(heatmap, alpha=0.5, cmap='jet')\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Pred: {preds[i].item()}, True: {labels[i].item()}\")\n",
        "            plt.show()\n",
        "\n",
        "            images_shown += 1\n",
        "            if images_shown >= num_images:\n",
        "                return\n"
      ],
      "metadata": {
        "id": "qgdIAeJkJORF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last conv layer in DRResNet\n",
        "target_layer = model.layer4[1].conv2\n",
        "visualize_gradcam(model, test_loader, target_layer, device, num_images=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qZzFN2f3JYEe",
        "outputId": "b485f693-3f90-428a-cfb7-95169cddcaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAGrCAYAAADn6WHYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAD/JJREFUeJzt3X+sVwX9x/H3dRe9/HDuasD4JSATh35R+2r4nVjDH6WJ+/qHwzmqgSsi+rEam1vZRDNHzmiZUcFy06XQFnPM1fqjbOB3Or+h3zW/mZINQyOZ4lI2TBDkfP9w3G83bnLv9fXxDHw8tvvHPed8zud9zth9fs75fD6jq2mapgDgXTqu7QEAODYICgARggJAhKAAECEoAEQICgARggJAhKAAECEoAEQICkedadOm1eLFi9seA/gngsKQ3HvvvdXV1dX309PTUzNnzqwvfvGL9dJLL7U93qAcPHiw7rjjjpo+fXr19PTU2WefXT/96U+Hta958+b1Ox//6ueWW27JHkTQM888U1dccUWNGTOmTj755PrUpz5Vu3btanssjkLdbQ/A0enWW2+t6dOn1969e+uRRx6pH/3oR/XLX/6ynnrqqRo1alTb472jr3/963X77bfXkiVL6kMf+lA9+OCDtXDhwurq6qrrrrtuyPv6zGc+0/f7448/XnfddVfdeOONNWvWrL7lZ599dmz+pB07dtRHPvKROumkk2rlypW1Z8+eWrVqVf3+97+vLVu21PHHH9/2iBxNGhiCe+65p6mq5vHHH++3fPny5U1VNevXr/+Xj92zZ09khqlTpzaLFi0a1mN37NjRjBgxovnCF77Qt+zgwYPNhz/84Wby5MnNgQMH3tVsGzZsaKqq2bRp0ztulzoX79ayZcuakSNHNs8//3zfsl//+tdNVTVr165tcTKORm55EXHJJZdUVdWf//znqqpavHhxjRkzprZt21ZXXnllnXjiifWJT3yiqt6+5XTnnXfWWWedVT09PTV+/PhaunRpvfrqq/322TRN3XbbbTV58uQaNWpUXXzxxfWHP/xhwOfftm1bbdu27YhzPvjgg7V///76/Oc/37esq6urli1bVjt27KjHHntsWMf/Tm655Zbq6uqqp59+uhYuXFi9vb110UUXVdXbt8zmzZt32GMWL15c06ZN67dssOdt9+7dtXXr1tq9e/cRZ3vggQfqqquuqlNPPbVv2WWXXVYzZ86sn/3sZ0M/WN7XBIWIQ3/MTznllL5lBw4cqMsvv7zGjRtXq1atqmuuuaaqqpYuXVo33HBDzZ07t773ve/V9ddfX+vWravLL7+89u/f3/f4FStW1E033VTnnHNOffvb367TTjutPvaxj9Xrr79+2PNfeumldemllx5xzt/97nc1evTofrejqqrmzJnTt75TFixYUH//+99r5cqVtWTJkiE/frDnbePGjTVr1qzauHHjO+7vr3/9a7388st1/vnnH7Zuzpw5HT0XHJu8h8Kw7N69u1555ZXau3dvPfroo3XrrbfWyJEj66qrrurbZt++fbVgwYL61re+1bfskUceqbvvvrvWrVtXCxcu7Ft+8cUX1xVXXFEbNmyohQsX1q5du+qOO+6o+fPn189//vPq6uqqqrffs1i5cuWw5965c2eNHz++b3+HTJgwoaqqXnzxxWHv+0jOOeecWr9+/bAeO9jzNhQ7d+6sqv8/9n80YcKE+tvf/lb79u2rE044YVgz8/7jCoVhueyyy2rs2LE1ZcqUuu6662rMmDG1cePGmjRpUr/tli1b1u/3DRs21EknnVQf/ehH65VXXun7Oe+882rMmDG1adOmqqp66KGH6s0336wvfelL/f74f+UrXxlwnu3bt9f27duPOPcbb7wx4B/Inp6evvWd8rnPfW7Yjx3seat6+3ZZ0zRH/Gj1oWNt63xw7HGFwrD84Ac/qJkzZ1Z3d3eNHz++zjjjjDruuP6vT7q7u2vy5Mn9lv3pT3+q3bt317hx4wbc78svv1xVVc8//3xVVZ1++un91o8dO7Z6e3uHPffIkSNr3759hy3fu3dv3/pOmT59+rAfO9jzNhSHjrWt88GxR1AYljlz5gx47/0fnXDCCYdF5uDBgzVu3Lhat27dgI8ZO3ZsbMaBTJgwoTZt2lRN0/S78jl0+2fixIkde+6B/jh3dXVVM8D/wv3WW2/1+70T5+3Qra5Dx/6Pdu7cWSeffLLbXQyJoPCemjFjRj300EM1d+7cd3z1O3Xq1Kp6+5X5aaed1rd8165dh32qaSjOPffcuvvuu+uZZ56pM888s2/5b3/7277176Xe3t567rnnDlt+6ArtkMGet6GYNGlSjR07tp544onD1m3ZsuU9Pxcc/byHwnvq2muvrbfeequ++c1vHrbuwIED9dprr1XV2+/RjBgxor7//e/3ewV/5513DrjfwX5s+Oqrr64RI0bUD3/4w75lTdPUmjVratKkSXXhhRcO7YDepRkzZtTWrVv7fTP9ySefrEcffbTfdoM9b1VD+9jwNddcU7/4xS/qL3/5S9+y3/zmN/Xss8/WggULhnFEvK+1+SUYjj7/6ouN/2zRokXN6NGjB1y3dOnSpqqaj3/84813v/vdZvXq1c2Xv/zlZuLEic2GDRv6tvva177WVFVz5ZVXNqtXr24+/elPNxMnTmw+8IEPHPbFxqlTpzZTp04d1DHccMMNTVU1n/3sZ5sf//jHzfz585uqatatWzfgsd5zzz2D2m/TDPzFxptvvrmpqmbXrl2Hbf/00083xx13XPPBD36wWb16dbNixYpm3LhxzezZsw87nsGet6HM/cILLzSnnHJKM2PGjOauu+5qVq5c2fT29jazZ89u9u7dO+jjhqZpGre8eM+tWbOmzjvvvFq7dm3deOON1d3dXdOmTatPfvKTNXfu3L7tbrvtturp6ak1a9bUpk2b6oILLqhf/epXNX/+/Hf1/Lfffnv19vbW2rVr6957763TTz+97r///sM+drtnz56qGvhjtSmzZs2qn/zkJ7VixYpavnx5nXnmmXXffffV+vXra/Pmzf22Hex5G4opU6bUww8/XMuXL6+vfvWrdfzxx9f8+fPrO9/5jvdPGLKuphngHUGgrr322tq+fXtt2bKl7VHgqOAKBQbQNE1t3ry57r///rZHgaOGKxQAInzKC4AIQQEgQlAAiBAUACIEBYCIQX9seN+S04680VHqgVP/s+0ROuap585te4TOeantATrozbYH6KCetgfonDMueKrtETpm0U2rjriNKxQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgIjuQW+5p4NTtGzr3jPaHqFz7mt7gE56ou0BOuj1tgfooJltD9Axf5zyb22P0CpXKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEd2D3vIYTk9z8Bg+uHPbHqCDZp/f9gSdcwz/k6zH2h6gc8ZMfK3tEVp1LP+zBeA9JCgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARHQPessDHZyiZTNHPdv2CB1z/tX/0/YIHfPGN15oe4SOmdD2AB305M0XtT1Cx7xYE9seoVWuUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIroHveWrHZyiZf9R/932CB1z6v/ubHuEjtnc9gAddNa/tz1B5/zXHy9pe4TO2dr2AB1005E3cYUCQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABDRPegtX+/gFC3rrdfaHqFzprY9QOfMu77tCTrn4VMvbHuEzvnGwbYn6KD392v09/fRAxAjKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABEdA96y/0dnKJlJ774RtsjdM7rbQ/QQaPbHqBzZtazbY/QMU/cfH7bI3TMgQMj2h6hVa5QAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiupqmadoeAoCjnysUACIEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACL+D6XrkNlSeNpfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAGrCAYAAADn6WHYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEBJJREFUeJzt3X+s1wW9x/H3cQc4/CjvwYDxwwC50NAhdS3aorqapga22hzOUV5xpUTWamzelU1y5siZLTNUWO7qUmiLNXJ1/SNt2KbXhW3Na6mrkVgkCV4VLxoo8Ll/OM7txEnOOb6+fgY9Htv543w+n+/nvD8ftu/z+/l8v9/R1TRNUwDwBh3X9gAAHBsEBYAIQQEgQlAAiBAUACIEBYAIQQEgQlAAiBAUACIEhaPOjBkzatmyZW2PAfwNQWFI7rjjjurq6ur76enpqTlz5tTnPve5euaZZ9oeb1AOHjxY119/fc2cObN6enrq1FNPre9///vD2tfpp5/e73z8vZ+rr746exBBjz/+eJ177rk1bty4Gj9+fF100UW1a9eutsfiKNTd9gAcna655pqaOXNm7d27tx544IG69dZb65577qlf//rXNWbMmLbHe11f+cpX6rrrrqtLL7203vOe99Tdd99dS5cura6urrrwwguHvK9Pf/rTfb8//PDDddNNN9WVV15Zc+fO7Vt+6qmnxuZP2r59e33wgx+s448/vlavXl179uypG264oR599NHasmVLjRw5su0ROZo0MAS33357U1XNww8/3G/5ypUrm6pqNmzY8Hcfu2fPnsgM06dPby6++OJhPXb79u3NiBEjmssvv7xv2cGDB5sPfOADzbRp05r9+/e/odk2btzYVFWzefPm190udS7eqBUrVjSjR49unnrqqb5l9957b1NVzbp161qcjKORW15EfOhDH6qqqieffLKqqpYtW1bjxo2rrVu31qJFi+otb3lLfeITn6iq12453XjjjXXKKadUT09PTZo0qZYvX17PP/98v302TVPXXnttTZs2rcaMGVNnnHFG/eY3vxnw72/durW2bt16xDnvvvvuevXVV+uzn/1s37Kurq5asWJFbd++vR566KFhHf/rufrqq6urq6see+yxWrp0afX29tb73//+qnrtltnpp59+2GOWLVtWM2bM6LdssOdt9+7d9cQTT9Tu3buPONsPf/jDOu+88+rtb39737Kzzjqr5syZUz/4wQ+GfrD8QxMUIg49mZ9wwgl9y/bv31/nnHNOTZw4sW644YY6//zzq6pq+fLldcUVV9TChQvr29/+dl1yySW1fv36Ouecc+rVV1/te/yqVavqqquuqvnz59c3vvGNOumkk+rss8+ul1566bC/f+aZZ9aZZ555xDl/9atf1dixY/vdjqqqWrBgQd/6TlmyZEm9/PLLtXr16rr00kuH/PjBnrdNmzbV3Llza9OmTa+7vz/96U+1c+fOeve7333YugULFnT0XHBs8h4Kw7J79+569tlna+/evfXggw/WNddcU6NHj67zzjuvb5t9+/bVkiVL6utf/3rfsgceeKBuu+22Wr9+fS1durRv+RlnnFHnnntubdy4sZYuXVq7du2q66+/vhYvXlw//vGPq6urq6pee89i9erVw557x44dNWnSpL79HTJ58uSqqnr66aeHve8jmT9/fm3YsGFYjx3seRuKHTt2VNX/H/tfmzx5cj333HO1b9++GjVq1LBm5h+PKxSG5ayzzqoJEybUiSeeWBdeeGGNGzeuNm3aVFOnTu233YoVK/r9vnHjxjr++OPrwx/+cD377LN9P6eddlqNGzeuNm/eXFVV9913X73yyiv1+c9/vt+T/xe/+MUB59m2bVtt27btiHP/5S9/GfAJsqenp299p3zmM58Z9mMHe96qXrtd1jTNET9afehY2zofHHtcoTAsN998c82ZM6e6u7tr0qRJ9Y53vKOOO67/65Pu7u6aNm1av2W/+93vavfu3TVx4sQB97tz586qqnrqqaeqqmr27Nn91k+YMKF6e3uHPffo0aNr3759hy3fu3dv3/pOmTlz5rAfO9jzNhSHjrWt88GxR1AYlgULFgx47/2vjRo16rDIHDx4sCZOnFjr168f8DETJkyIzTiQyZMn1+bNm6tpmn5XPodu/0yZMqVjf3ugJ+eurq5qBvhfuA8cONDv906ct0O3ug4d+1/bsWNHjR8/3u0uhkRQeFPNmjWr7rvvvlq4cOHrvvqdPn16Vb32yvykk07qW75r167DPtU0FO985zvrtttuq8cff7xOPvnkvuW/+MUv+ta/mXp7e+v3v//9YcsPXaEdMtjzNhRTp06tCRMm1C9/+cvD1m3ZsuVNPxcc/byHwpvqggsuqAMHDtTXvva1w9bt37+/Xnjhhap67T2aESNG1He+851+r+BvvPHGAfc72I8Nf+xjH6sRI0bULbfc0resaZpau3ZtTZ06td73vvcN7YDeoFmzZtUTTzzR75vpjzzySD344IP9thvseasa2seGzz///PrJT35Sf/zjH/uW/exnP6vf/va3tWTJkmEcEf/Q2vwSDEefv/fFxr918cUXN2PHjh1w3fLly5uqaj7ykY803/rWt5o1a9Y0X/jCF5opU6Y0Gzdu7Nvuy1/+clNVzaJFi5o1a9Y0n/rUp5opU6Y0b3vb2w77YuP06dOb6dOnD+oYrrjiiqaqmssuu6z57ne/2yxevLipqmb9+vUDHuvtt98+qP02zcBfbPzqV7/aVFWza9euw7Z/7LHHmuOOO65517ve1axZs6ZZtWpVM3HixGbevHmHHc9gz9tQ5v7DH/7QnHDCCc2sWbOam266qVm9enXT29vbzJs3r9m7d++gjxuapmnc8uJNt3bt2jrttNNq3bp1deWVV1Z3d3fNmDGjPvnJT9bChQv7trv22murp6en1q5dW5s3b673vve99dOf/rQWL178hv7+ddddV729vbVu3bq64447avbs2XXXXXcd9rHbPXv2VNXAH6tNmTt3bn3ve9+rVatW1cqVK+vkk0+uO++8szZs2FD3339/v20He96G4sQTT6yf//zntXLlyvrSl75UI0eOrMWLF9c3v/lN758wZF1NM8A7gkBdcMEFtW3bttqyZUvbo8BRwRUKDKBpmrr//vvrrrvuansUOGq4QgEgwqe8AIgQFAAiBAWACEEBIEJQAIgY9MeGL/uPf+vkHK26pxa1PULHvHjv+LZH6Jz/anuADjqG/9nquRfbnqBzpry17Qk65sWHzj7iNq5QAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiuge74ch6pZNztOqV/SPbHqFz/tz2AJ20re0BOue5/W1P0EHb2x6gc56e3fYErXKFAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQ0T3YDd9auzs5R6smdu9se4SO+Z+LDrQ9QseMrLFtj9Axzz8zoe0ROudH/9z2BJ1zDB/aYLhCASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACIEBQAIgQFgAhBASBCUACI6B7shq/WiE7O0aoT6tm2R+iYS3be2fYIHXP/rW1P0Dn/OrrtCTrnv//9lLZH6JgX6p/aHqGDzj7iFq5QAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiBAWACEEBIEJQAIgQFAAiuge74Yv11k7O0apH985re4SOOTjx2H3N8PGP/mfbI3TOmLYH6Jwf/e/H2x6hc14c9FPqMenYfbYB4E0lKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEYICQISgABAhKABEdA92w1H1SifnaNWIkfvbHqFjnq/xbY/QMZv+5aNtj9Ax22tq2yN0zs2Dfto5+rzc9gAddNWRN3GFAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQ0T3YDXvruU7O0ar5xz3S9ggdM7ZeanuEjtlWM9oeoWMm15/bHqFjui8/0PYIHbPzySltj9AqVygARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABGCAkCEoAAQISgARAgKABFdTdM0bQ8BwNHPFQoAEYICQISgABAhKABECAoAEYICQISgABAhKABECAoAEf8HlaGXvmb0e7cAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cb7-lgGm9NM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}